{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a7b1245-aa59-4143-9440-fc5007be7aa8",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f63805f6-6570-4324-a11d-26a1021f518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a0069-f756-48b3-80a2-16b160209b66",
   "metadata": {},
   "source": [
    "## Preprocessing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbcb5592-480b-4d5b-9259-4dc2c114ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \n",
    "when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into \n",
    "electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, \n",
    "and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad31605e-dbff-4fdd-b4fb-6fb93fd9dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_without_stopwords(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in stopwords.words(\"english\")]\n",
    "    lemmatized = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    stemmed = [stemmer.stem(token) for token in lemmatized]\n",
    "    return \" \".join(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaebcb7e-f1e4-45f4-bc98-3319e9b29c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lorem ipsum simpli dummi text print typeset industri lorem ipsum industri standard dummi text ever sinc 1500 unknown printer took galley type scrambl make type specimen book surviv five centuri also leap electron typeset remain essenti unchang popularis 1960 releas letraset sheet contain lorem ipsum passag recent desktop publish softwar like aldu pagemak includ version lorem ipsum'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_without_stopwords(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00949f6b-adf6-47f1-92ed-21ca3c275e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_with_stopwords(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    lemmatized = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    stemmed = [stemmer.stem(token) for token in lemmatized]\n",
    "    return \" \".join(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4b9439f-d78a-4cf8-b9b6-c121dd98f8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lorem ipsum is simpli dummi text of the print and typeset industri lorem ipsum ha been the industri standard dummi text ever sinc the 1500 when an unknown printer took a galley of type and scrambl it to make a type specimen book it ha surviv not onli five centuri but also the leap into electron typeset remain essenti unchang it wa popularis in the 1960 with the releas of letraset sheet contain lorem ipsum passag and more recent with desktop publish softwar like aldu pagemak includ version of lorem ipsum'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_with_stopwords(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4bf8f7-a72d-4f43-bd42-f94a5817580f",
   "metadata": {},
   "source": [
    "## Loading Data for chat bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aa264a3-8b1f-4ddb-8022-1fad34fe4756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Education Qualification Marks Results study</td>\n",
       "      <td>\"Class 10 From Chandrakant Patil English mediu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skills</td>\n",
       "      <td>\"Programming Languages : Python | Database Too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Contact number email mail</td>\n",
       "      <td>\"Mobile: +917899678022 | Email: akash.hiremath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GitHub Repository Projects Project</td>\n",
       "      <td>https://github.com/AkashHiremath856/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blogs blog Experience</td>\n",
       "      <td>No prior experience but check out my work http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Portfolio Website</td>\n",
       "      <td>https://akashhiremath856.github.io/MyPortfolio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Personal Information about bio</td>\n",
       "      <td>\"Akash\\nHighly motivated and detail-oriented, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Questions  \\\n",
       "0  Education Qualification Marks Results study   \n",
       "1                                       Skills   \n",
       "2                    Contact number email mail   \n",
       "3           GitHub Repository Projects Project   \n",
       "4                        Blogs blog Experience   \n",
       "5                            Portfolio Website   \n",
       "6               Personal Information about bio   \n",
       "\n",
       "                                             Answers  \n",
       "0  \"Class 10 From Chandrakant Patil English mediu...  \n",
       "1  \"Programming Languages : Python | Database Too...  \n",
       "2  \"Mobile: +917899678022 | Email: akash.hiremath...  \n",
       "3               https://github.com/AkashHiremath856/  \n",
       "4  No prior experience but check out my work http...  \n",
       "5  https://akashhiremath856.github.io/MyPortfolio...  \n",
       "6  \"Akash\\nHighly motivated and detail-oriented, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67367b37-55b6-4339-8167-461f91e64e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "questions_list = data[\"Questions\"]\n",
    "answers_list = data[\"Answers\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=nltk.word_tokenize)\n",
    "X = vectorizer.fit_transform([preprocess_without_stopwords(q) for q in questions_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5709f8ee-ec8c-4ed2-aeca-58a74fd72fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Mobile: +917899678022 | Email: akash.hiremath25@gmail.com| LinkedIn: www.linkedin.com/in/akash-hiremath25\"\n"
     ]
    }
   ],
   "source": [
    "def get_response(text):\n",
    "    preprocessed_text = preprocess_with_stopwords(text)\n",
    "    vectorized_text = vectorizer.transform([preprocessed_text])\n",
    "    similarities = cosine_similarity(vectorized_text, X)\n",
    "    max_similarity = np.max(similarities)\n",
    "    if max_similarity >= 0.5:\n",
    "        high_similarity_questions = [\n",
    "            q for q, s in zip(questions_list, similarities[0]) if s >= 0.5\n",
    "        ]\n",
    "\n",
    "        target_answers = []\n",
    "        for q in high_similarity_questions:\n",
    "            target_answers.append(data[data[\"Questions\"] == q][\"Answers\"].values[0])\n",
    "        print(target_answers[0])\n",
    "\n",
    "\n",
    "get_response(\"email\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
